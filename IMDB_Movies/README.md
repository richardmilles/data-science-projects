#  Pr√©diction du succ√®s financier des films IMDB

## 1. Introduction

Ce projet de data science vise √† pr√©dire le **revenu brut (Gross)** des films √† partir de leurs caract√©ristiques, en se basant sur le dataset **IMDB Movies Dataset** disponible sur Kaggle.

L‚Äôobjectif principal est de construire un mod√®le capable d'estimer le succ√®s commercial d‚Äôun film **avant sa sortie**, en exploitant des informations telles que :
- Le nom des **acteurs** et du **r√©alisateur**
- Le **genre** du film
- Sa **dur√©e**
- Son **ann√©e de sortie**
- Son **certificat de classification**
- Le **nombre de votes IMDB**, etc.

###  Contexte
Le dataset contient 1 000 films parmi les mieux not√©s sur IMDB, avec des variables comme :
- `Series_Title`, `Director`, `Stars`, `Genre`, `Runtime`, `Certificate`
- `IMDB_Rating`, `Meta_score`, `No_of_votes`, `Gross` (la cible √† pr√©dire)

Ce projet a √©t√© r√©alis√© dans une logique **d‚Äôapprentissage par la pratique**, en appliquant toutes les √©tapes cl√©s d‚Äôun cycle de data science :
1. Exploration et nettoyage des donn√©es
2. Pr√©paration des variables
3. Mod√©lisation et √©valuation
4. Interpr√©tation des r√©sultats

Le but final : **comprendre les facteurs qui influencent r√©ellement le revenu d‚Äôun film** et construire un mod√®le robuste pour en faire la pr√©diction.

## 2.  Exploration des donn√©es (EDA)

Avant toute mod√©lisation, une √©tape d'exploration et de compr√©hension des donn√©es a √©t√© r√©alis√©e.

###  Description du dataset

Le dataset contient **1 000 films** avec les variables suivantes :

| Variable         | Description |
|------------------|-------------|
| `Series_Title`   | Titre du film |
| `Released_Year`  | Ann√©e de sortie |
| `Certificate`    | Classification du film (ex : PG-13, R, U) |
| `Runtime`        | Dur√©e du film (ex : "142 min") |
| `Genre`          | Genres du film (ex : "Action, Drama, Sci-Fi") |
| `IMDB_Rating`    | Note moyenne sur IMDB |
| `Meta_score`     | Score Metacritic |
| `Director`       | R√©alisateur |
| `Star1` √† `Star4`| Acteurs principaux |
| `No_of_Votes`    | Nombre de votes re√ßus sur IMDB |
| `Gross`          | Revenu brut g√©n√©r√© par le film (en $) |

###  Donn√©es manquantes

- `Certificate` : 101 valeurs manquantes  
- `Meta_score` : 157 valeurs manquantes  
- `Gross` : 169 valeurs manquantes (notre **variable cible**)

Des d√©cisions ont √©t√© prises :
- Remplacer les valeurs manquantes de `Meta_score` par sa **moyenne**
- Remplacer `Certificate` par sa **valeur la plus fr√©quente**
- Supprimer les lignes o√π `Gross` est manquant (car non pr√©dictible)

### üìä Visualisations exploratoires

Plusieurs visualisations ont √©t√© r√©alis√©es pour mieux comprendre les donn√©es :

- **Distribution de `Gross`** : tr√®s asym√©trique, avec quelques blockbusters extr√™mes
- **Corr√©lation entre variables** : `No_of_Votes` est la plus corr√©l√©e √† `Gross` (0.57)
- **Genres les plus rentables** : `Adventure`, `Sci-Fi`, `Action` dominent
- **R√©alisateurs les plus bankables** : Anthony Russo, James Cameron, J.J. Abrams...
- **Tendance temporelle** : les films r√©cents ont tendance √† rapporter davantage

---

## 3.  Pr√©paration des donn√©es

###  Traitement des variables cat√©goriques

Les colonnes comme `Genre`, `Certificate`, `Director`, `Star1‚Äì4` ont √©t√© encod√©es :

- `Genre`, `Certificate` : **One-Hot Encoding**
- `Director`, `Stars` : **Target Encoding** bas√© sur le revenu moyen par personne
  - Les 4 colonnes `Star1‚Äì4` ont √©t√© combin√©es et remplac√©es par un score moyen `Stars_encoded`

###  Transformation de la variable cible

Le revenu (`Gross`) ayant une distribution tr√®s asym√©trique, on a appliqu√© une **transformation logarithmique** :
```python
df['log_Gross'] = np.log(df['Gross'] + 1)
```
Cela rend la distribution plus normale et am√©liore l‚Äôapprentissage des mod√®les de r√©gression.

##  Normalisation des variables num√©riques

- Les variables num√©riques (No_of_Votes, Runtime, Stars_encoded, etc.) ont √©t√© standardis√©es avec StandardScaler
- La variable cible Gross n‚Äôa pas √©t√© normalis√©e, mais seulement transform√©e en log.

## Split du dataset

Le dataset a √©t√© s√©par√© en 3 parties :

- 70% Entra√Ænement (X_train, y_train)
- 15% Validation (X_val, y_val)
- 15% Test final (X_test, y_test)

## 4.  Mod√©lisation

L‚Äôobjectif est de pr√©dire le revenu brut (`Gross`) d‚Äôun film √† partir de ses caract√©ristiques.  
Plusieurs mod√®les de r√©gression ont √©t√© test√©s, en commen√ßant par un mod√®le simple, puis en allant vers des mod√®les plus puissants.

---

###  R√©gression lin√©aire (baseline)

Un premier mod√®le **de r√©gression lin√©aire** a √©t√© entra√Æn√© sur la variable transform√©e `log(Gross)`.

#### R√©sultat :
Les performances obtenues √©taient **extr√™mement mauvaises** :

- **MAE :** valeurs astronomiques
- **R¬≤ :** fortement n√©gatif (pire qu‚Äôun mod√®le qui pr√©dit la moyenne)

 **Interpr√©tation** : la relation entre les variables et le revenu n‚Äôest **pas lin√©aire**, donc ce mod√®le est **inadapt√©**.

---

###  Random Forest Regressor

Un mod√®le **Random Forest**, bas√© sur un ensemble d‚Äôarbres de d√©cision, a ensuite √©t√© utilis√©.

####  Avantages :
- Capte les **relations non lin√©aires**
- G√®re bien les **interactions entre variables**
- R√©sistant aux outliers
- Aucun besoin de normalisation des variables

####  R√©sultats (validation) :
- **MAE :** 14,4 M $
- **RMSE :** 34,8 M $
- **R¬≤ :** 0.8700

Ces r√©sultats montrent que le mod√®le est **tr√®s performant**, expliquant plus de 87% de la variance des revenus sur des films jamais vus √† l'entra√Ænement.

---

### ‚öôÔ∏è Optimisation avec GridSearchCV

Une recherche d'hyperparam√®tres (`n_estimators`, `max_depth`, etc.) a √©t√© men√©e pour affiner le mod√®le.

R√©sultat : les performances sont rest√©es **quasiment identiques**, ce qui confirme que le mod√®le initial √©tait d√©j√† tr√®s bien ajust√©.

---

###  Test d‚Äôun mod√®le XGBoost

Un mod√®le **XGBoost** (Extreme Gradient Boosting) a √©galement √©t√© test√©.  
Ce mod√®le est tr√®s performant sur de nombreux probl√®mes, mais dans ce cas pr√©cis, il a l√©g√®rement **sous-perform√©** compar√© √† Random Forest.

####  R√©sultats XGBoost (validation) :
- **MAE :** 15,5 M $
- **RMSE :** 38,2 M $
- **R¬≤ :** 0.8438

> Conclusion : le **Random Forest** reste le **mod√®le optimal** pour ce projet.

---

###  √âvaluation finale sur le jeu de test

Le mod√®le Random Forest a ensuite √©t√© test√© sur les **donn√©es totalement in√©dites** (`X_test`, `y_test`), avec la transformation inverse du logarithme appliqu√©e aux pr√©dictions.

####  R√©sultats sur test final :
- **MAE :** 18,1 M $
- **RMSE :** 40,0 M $
- **R¬≤ :** 0.8642 

 Cela confirme que le mod√®le est **robuste, fiable et g√©n√©ralisable**.


## 5.  √âvaluation des performances et importance des variables

###  M√©triques utilis√©es

Trois m√©triques ont √©t√© utilis√©es pour √©valuer la performance des mod√®les :

| M√©trique | Description |
|---------|-------------|
| **MAE (Mean Absolute Error)** | Erreur moyenne absolue : donne une id√©e directe de l'√©cart moyen entre la pr√©diction et la r√©alit√© |
| **RMSE (Root Mean Squared Error)** | P√©nalise davantage les grosses erreurs que le MAE |
| **R¬≤ (coefficient de d√©termination)** | Mesure la proportion de la variance expliqu√©e par le mod√®le (entre 0 et 1 id√©alement) |

---

###  R√©sum√© des performances finales du mod√®le Random Forest

| Jeu de donn√©es | MAE (en $) | RMSE (en $) | R¬≤ |
|----------------|-------------|-------------|-----|
| **Validation** | 14,455,614 | 34,857,261 | 0.8700 |
| **Test final** | 18,135,556 | 40,056,388 | 0.8642  |

>  Le mod√®le est capable de pr√©dire les revenus d‚Äôun film avec **moins de 20 millions d‚Äôerreur moyenne**, ce qui est excellent compte tenu de la variabilit√© des films (certains rapportant quelques millions, d'autres plusieurs centaines).

---

###  Importance des variables

Le mod√®le Random Forest permet d‚Äôanalyser **l‚Äôimportance relative de chaque variable** dans la pr√©diction du revenu.

####  Top 10 des variables les plus importantes :

1. **Stars_encoded** ‚Üí Niveau "bankable" des acteurs
2. **Director_encoded** ‚Üí R√©putation du r√©alisateur
3. **Released_Year** ‚Üí Tendance des films r√©cents √† rapporter plus
4. **Genre_Crime, Thriller**
5. **No_of_Votes** ‚Üí Popularit√© sur IMDB
6. **Runtime** ‚Üí Longueur du film
7. **Genre_Drama, History**
8. **Genre_Drama**
9. **Genre_Comedy, Drama, War**
10. **Certificate_Passed**

####  Interpr√©tation :

- Les variables **Stars_encoded** et **Director_encoded** dominent clairement, montrant que **le casting et le r√©alisateur sont les meilleurs pr√©dicteurs du succ√®s**.
- Le **genre**, le **nombre de votes** et la **dur√©e** du film ont une influence plus marginale.
- Le **certificat de classification** (ex : PG-13, R...) semble peu d√©terminant.

 Ces r√©sultats sont coh√©rents avec l‚Äôintuition m√©tier : les **grands noms attirent l‚Äôaudience**, et donc les revenus.

## 6.  Conclusion et interpr√©tation m√©tier

###  Objectif atteint

L‚Äôobjectif de ce projet √©tait de **pr√©dire le revenu brut (`Gross`) d‚Äôun film** √† partir de ses caract√©ristiques disponibles **avant sa sortie**.  
Gr√¢ce √† un traitement rigoureux des donn√©es, une mod√©lisation adapt√©e et des tests approfondis, un **mod√®le performant et g√©n√©ralisable** a √©t√© construit.

###  R√©sum√© des √©tapes cl√©s

- **Exploration du dataset IMDB** pour comprendre les tendances g√©n√©rales
- **Nettoyage et transformation** des donn√©es, y compris la transformation log de la cible
- **Encodage intelligent** des variables cat√©goriques comme `Stars`, `Director`, `Genre`
- **Test de plusieurs mod√®les**, dont Linear Regression (baseline), Random Forest (final), et XGBoost (comparatif)
- **Optimisation des hyperparam√®tres** avec GridSearch
- **√âvaluation finale sur donn√©es in√©dites** avec des m√©triques solides (R¬≤ ‚âà 0.86)

---

###  Ce que nous apprend le mod√®le

L‚Äôanalyse des variables les plus importantes r√©v√®le des **enseignements tr√®s clairs** :

- Les **acteurs principaux** (`Stars_encoded`) et le **r√©alisateur** (`Director_encoded`) sont **les deux facteurs les plus pr√©dictifs** du succ√®s commercial d‚Äôun film.
- Les variables comme le **genre**, le **nombre de votes IMDB**, ou la **dur√©e du film** ont un **impact plus limit√©**.
- Le **certificat de classification** (PG-13, R...) a une influence marginale.

 En d'autres termes, le **casting** et le **talent derri√®re la cam√©ra** sont les √©l√©ments d√©terminants pour maximiser les revenus d‚Äôun film.


### Perspectives et limites

#### Points forts :
- Mod√®le performant, explicable et reproductible
- Pipeline complet de bout en bout
- R√©sultats interpr√©tables gr√¢ce √† l‚Äôanalyse des importances

####  Limites :
- Donn√©es limit√©es √† 1 000 films ‚Üí pas repr√©sentatif de toute l'industrie
- Certaines variables comme `Overview` ou les budgets n‚Äô√©taient pas exploit√©es
- Le mod√®le ne prend pas en compte les effets de campagne marketing, date de sortie, etc.

---

###  Am√©liorations possibles

- Int√©grer des techniques NLP sur `Overview` (r√©sum√© du film)
- Utiliser des donn√©es suppl√©mentaires (budget, studio, date exacte de sortie)
- Tester d'autres algorithmes de boosting (CatBoost, LightGBM)
- D√©ployer le mod√®le dans une application interactive (API ou dashboard)

---


Ce projet montre qu‚Äôil est possible de **pr√©dire avec une bonne pr√©cision le succ√®s financier d‚Äôun film** √† partir de variables simples, **en particulier li√©es au casting et au r√©alisateur**.  
C‚Äôest une d√©monstration concr√®te de la **valeur pr√©dictive des donn√©es** dans un contexte artistique et √©conomique comme le cin√©ma.

> Merci de votre lecture   













